<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="TSHOGX">


    <meta name="subtitle" content="Valar Morghulis  Valar Dohaeris">




<title>ç»Ÿè®¡å­¦ä¹ ç†è®º | -TSHOGX-</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
            <!-- MathJaxé…ç½®ï¼Œå¯é€šè¿‡å•ç¾å…ƒç¬¦å·ä¹¦å†™è¡Œå†…å…¬å¼ç­‰ -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- ç»™MathJaxå…ƒç´ æ·»åŠ has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- é€šè¿‡è¿æ¥CDNåŠ è½½MathJaxçš„jsä»£ç  -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 4.2.0"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">TSHOGX&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">TSHOGX&#39;s Blog</a><a id="mobile-toggle-theme">Â·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">ç»Ÿè®¡å­¦ä¹ ç†è®º</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">TSHOGX</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">April 17, 2020&nbsp;&nbsp;7:52:24</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/">è®¡ç®—æœº</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <p>æ›´æ–°æ—¶é—´ï¼š5.25 Dell</p>
<p>ç»Ÿè®¡å­¦ä¹ æ˜¯åŸºäºæ•°æ®æ„å»ºç»Ÿè®¡æ¨¡å‹è€Œå¯¹æ•°æ®é¢„æµ‹åˆ†æï¼ŒåŒ…æ‹¬ supervisedã€unsupervisedã€semi-supervisedã€reinforcement ç­‰</p>
<p>å¯¹äºsupervisedæ¥è¯´ï¼Œæˆ‘ä»¬å¸Œæœ›æ‰¾åˆ° input space åˆ° output space çš„æ˜ å°„ï¼Œæ‰€æœ‰è¿™æ ·çš„æ˜ å°„/æ¨¡å‹æ„æˆçš„é›†åˆå°±æ˜¯ hypothesis spaceï¼Œå³æˆ‘ä»¬çš„å­¦ä¹ èŒƒå›´</p>
<p>æ¨¡å‹å¯ä»¥æ˜¯å†³ç­–å‡½æ•° $Y=f(X)$ æˆ–è€…æ¦‚ç‡å‡½æ•° $P(y|x)$ï¼Œä¸è®ºå“ªç§æ¨¡å‹ï¼ŒXå’ŒYéƒ½å…·æœ‰è”åˆæ¦‚ç‡åˆ†å¸ƒ$P(X,Y)$ï¼Œè¿™æ˜¯ç›‘ç£å­¦ä¹ å…³äºæ•°æ®çš„åŸºæœ¬å‡è®¾ï¼Œå› æ­¤å¯ä»¥åˆ©ç”¨ç»Ÿè®¡çš„æ–¹æ³•å­¦ä¹ </p>
<p>ç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼š<br>perception 25-36 âœ”ï¸<br>knn 37-45 âœ”ï¸<br>naive bayes 47-53 âœ”ï¸<br>å†³ç­–æ ‘ 55-75<br>logisticså›å½’ æœ€å¤§ç†µæ¨¡å‹ 77-94<br>svm 95-134 âœ”ï¸<br>boosting 137-153 âœ”ï¸<br>em 155-170 âœ”ï¸<br>hmm 171-189 âœ”ï¸<br>conditional random field 191-210 âœ”ï¸</p>
<p>æœºå™¨å­¦ä¹  å‘¨ï¼š<br>çº¿å½¢æ¨¡å‹ âœ”ï¸<br>å†³ç­–æ ‘ âœ”ï¸<br>ç¥ç»ç½‘ç»œ âœ”ï¸<br>svm âœ”ï¸<br>è´å¶æ–¯åˆ†ç±» âœ”ï¸<br>é›†æˆå­¦ä¹  âœ”ï¸<br>èšç±» âœ”ï¸<br>é™ç»´ä¸åº¦é‡å­¦ä¹  âœ”ï¸<br>ç‰¹å¾é€‰æ‹©ä¸ç¨€ç–å­¦ä¹ <br>è®¡ç®—å­¦ä¹ ç†è®º âœ”ï¸<br>åŠç›‘ç£å­¦ä¹  âœ”ï¸<br>æ¦‚ç‡å›¾æ¨¡å‹ âœ”ï¸<br>è§„åˆ™å­¦ä¹ <br>å¼ºåŒ–å­¦ä¹  âœ”ï¸</p>
<ul>
<li><strong>åˆ¤åˆ«æ¨¡å‹</strong> discriminative modelï¼šç›´æ¥å­¦ä¹  $P(Y|X)$ or $f(X)$ ã€‚å›å½’ï¼Œknnï¼ŒSVM, æ¡ä»¶éšæœºåœºï¼Œboostingï¼Œå†³ç­–æ ‘ï¼Œæ„ŸçŸ¥æœºç­‰ã€‚ä¼˜ç‚¹ï¼šç›´æ¥é¢å¯¹é¢„æµ‹æ—¶ï¼Œå¾€å¾€æ­£ç¡®ç‡æ›´é«˜ï¼›ç›´æ¥å­¦ä¹ æ¨¡å‹ï¼Œç®€åŒ–å­¦ä¹ é—®é¢˜</li>
<li><strong>ç”Ÿæˆæ¨¡å‹</strong> generative modelï¼šå¯¹ $P(x,y)$ å»ºæ¨¡ï¼Œç”Ÿæˆæ¯ä¸ªlabelçš„æœ€ä¼˜æ¦‚ç‡ï¼Œ$P(Y|X) = \frac{P(X,Y)}{P(X)}$ã€‚æœ´ç´ è´å¶æ–¯, HMMç­‰ã€‚ä¼˜ç‚¹ï¼šè§£é‡Šæ€§å¥½ï¼Œå¯ä»¥è¿˜åŸå‡ºè”åˆæ¦‚ç‡åˆ†å¸ƒï¼›å­˜åœ¨éšå˜é‡ä¹Ÿè¡Œï¼›å­¦ä¹ æ—¶æ”¶æ•›é€Ÿåº¦æ›´å¿«</li>
</ul>
<h1 id="åˆ¤åˆ«åˆ†æ"><a href="#åˆ¤åˆ«åˆ†æ" class="headerlink" title="åˆ¤åˆ«åˆ†æ"></a>åˆ¤åˆ«åˆ†æ</h1><p>åˆ¤åˆ«åˆ†æ<strong>ï¼ˆdiscriminant analysisï¼‰</strong>æ˜¯å¤šå…ƒç»Ÿè®¡åˆ†æä¸­è¾ƒä¸ºæˆç†Ÿçš„ä¸€ç§åˆ†ç±»æ–¹æ³•ï¼Œå®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯<strong>â€œåˆ†ç±»ä¸åˆ¤æ–­â€</strong>ã€‚</p>
<h2 id="è·ç¦»åˆ¤åˆ«åŸºæœ¬ç†è®º"><a href="#è·ç¦»åˆ¤åˆ«åŸºæœ¬ç†è®º" class="headerlink" title="è·ç¦»åˆ¤åˆ«åŸºæœ¬ç†è®º"></a>è·ç¦»åˆ¤åˆ«åŸºæœ¬ç†è®º</h2><p>å‡è®¾å­˜åœ¨ä¸¤ä¸ªæ€»ä½“$G_1$å’Œ$G_2$ï¼Œå¦æœ‰$x$ä¸ºä¸€ä¸ª$p$ç»´çš„æ ·æœ¬å€¼ï¼Œè®¡ç®—å¾—åˆ°è¯¥æ ·æœ¬åˆ°ä¸¤ä¸ªæ€»ä½“çš„è·ç¦»$d(x,G_1)$å’Œ$d(x,G_2)$ï¼Œå¦‚æœ$d(x,G_1)$å¤§äº$d(x,G_2)$ï¼Œåˆ™è®¤ä¸ºæ ·æœ¬$x$å±äºæ€»ä½“$G_2$ï¼Œåä¹‹äº¦ç„¶ï¼›è‹¥ä¸¤è€…ç›¸ç­‰ï¼Œåˆ™è¯¥æ ·æœ¬å¾…åˆ¤ã€‚æ‰€ä»¥ï¼Œæœ€æ ¸å¿ƒçš„é—®é¢˜åœ¨äºè·ç¦»çš„è®¡ç®—ã€‚</p>
<ul>
<li>æ¬§å¼è·ç¦»ï¼šåœ¨è®¡ç®—å¤šä¸ªæ€»ä½“ä¹‹é—´çš„è·ç¦»æ—¶å¹¶ä¸è€ƒè™‘æ–¹å·®çš„å½±å“</li>
<li>é©¬æ°è·ç¦»ï¼šä¸å—æŒ‡æ ‡é‡çº²åŠæŒ‡æ ‡é—´ç›¸å…³æ€§çš„å½±å“ï¼ˆ$d^2_{ij} = (x_i-x_j)^T S^{-1}(x_i-x_j), S^{-1}$ ä¸ºæ€»ä½“ä¹‹é—´çš„åæ–¹å·®çŸ©é˜µï¼‰</li>
</ul>
<h2 id="è´å¶æ–¯åˆ¤åˆ«åŸºæœ¬ç†è®º"><a href="#è´å¶æ–¯åˆ¤åˆ«åŸºæœ¬ç†è®º" class="headerlink" title="è´å¶æ–¯åˆ¤åˆ«åŸºæœ¬ç†è®º"></a>è´å¶æ–¯åˆ¤åˆ«åŸºæœ¬ç†è®º</h2><p>å‰ææ˜¯å‡å®šæˆ‘ä»¬å·²ç»å¯¹æ‰€è¦åˆ†æçš„æ•°æ®æœ‰æ‰€äº†è§£ï¼ˆæ¯”å¦‚æ•°æ®æœä»ä»€ä¹ˆåˆ†åˆ«ï¼Œå„ä¸ªç±»åˆ«çš„å…ˆéªŒæ¦‚ç‡ç­‰ï¼‰</p>
<p>ä¸¤ç±»æ€»ä½“çš„æ¦‚ç‡å¯†åº¦å‡½æ•°å’Œå„è‡ªå‡ºç°çš„å…ˆéªŒæ¦‚ç‡å·²çŸ¥ï¼Œå³å¯æ¨æ–­æŸæ ·æœ¬$x_0$å‘ç”Ÿæ—¶ï¼Œä¸¤ç±»å‡ºç°çš„æ¦‚ç‡å¤§å°ï¼Œå³æ ·æœ¬å±äºä»¤åéªŒæ¦‚ç‡$P(G_i|x_0)$æœ€å¤§çš„$G$ã€‚</p>
<h2 id="Fisheråˆ¤åˆ«åŸºæœ¬ç†è®º"><a href="#Fisheråˆ¤åˆ«åŸºæœ¬ç†è®º" class="headerlink" title="Fisheråˆ¤åˆ«åŸºæœ¬ç†è®º"></a>Fisheråˆ¤åˆ«åŸºæœ¬ç†è®º</h2><p>Fisheråˆ¤åˆ«æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯â€œæŠ•å½±â€ï¼Œå°†$K$ç»„$P$ç»´çš„æ•°æ®å‘ä½ç»´ç©ºé—´æŠ•å½±ï¼Œä½¿å…¶æŠ•å½±çš„ç»„ä¸ç»„ä¹‹é—´çš„æ–¹å·®å°½å¯èƒ½çš„å¤§ï¼Œç»„å†…çš„æ–¹å·®å°½å¯èƒ½çš„å°ã€‚å› æ­¤ï¼ŒFisheråˆ¤åˆ«æ³•çš„é‡ç‚¹å°±æ˜¯é€‰æ‹©é€‚å½“çš„â€œæŠ•å½±è½´â€ã€‚åˆ¤åˆ«å‡½æ•°ä¸ºå°±æ˜¯é‚£ä¸ªè½´ã€‚</p>
<p>éçº¿æ€§åˆ¤åˆ«ï¼šåœ¨åˆ¤åˆ«åˆ†æçš„å®é™…åº”ç”¨ä¸­ï¼Œå¯¹å¤æ‚çš„æ•°æ®ä½¿ç”¨çº¿æ€§åˆ¤åˆ«å¯èƒ½æ— æ³•å¾—åˆ°ç†æƒ³çš„æ•ˆæœã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ç±»ä¼¼äºäºŒæ¬¡åˆ¤åˆ«å‡½æ•°çš„éçº¿æ€§åˆ†ç±»æ–¹æ³•ï¼Œå°†æ ·æœ¬ç‚¹æŠ•å½±åˆ°è‹¥å¹²ç§äºŒæ¬¡æ›²é¢ä¸­ï¼Œå®ç°ç†æƒ³çš„åˆ¤åˆ«æ•ˆæœã€‚</p>
<p><a href="https://zhuanlan.zhihu.com/The-Art-of-Data" target="_blank" rel="noopener">å‚è€ƒ</a></p>
<h2 id="å›å½’åˆ†æ"><a href="#å›å½’åˆ†æ" class="headerlink" title="å›å½’åˆ†æ"></a>å›å½’åˆ†æ</h2><p>å›å½’åˆ†ææ˜¯ä¸€ç§<strong>é¢„æµ‹</strong>æ€§çš„å»ºæ¨¡æŠ€æœ¯ï¼Œå®ƒä¼°è®¡äº†å› å˜é‡å’Œè‡ªå˜é‡ä¹‹é—´çš„å…³ç³»ï¼ˆå½±å“å¼ºåº¦å’Œå…·ä½“å…³ç³»ï¼‰ã€‚è¿™ç§æŠ€æœ¯é€šå¸¸ç”¨äºé¢„æµ‹åˆ†æï¼Œæ—¶é—´åºåˆ—æ¨¡å‹ä»¥åŠå‘ç°å˜é‡ä¹‹é—´çš„<strong>å› æœ</strong>å…³ç³»ã€‚</p>
<p>æ ¹æ®<strong>è‡ªå˜é‡çš„ä¸ªæ•°ï¼Œå› å˜é‡çš„ç±»å‹ä»¥åŠå›å½’çº¿çš„å½¢çŠ¶</strong>çš„ä¸åŒï¼Œæœ‰ä¸åŒå›å½’æ–¹æ³•ã€‚</p>
<p>åœ¨å„è‡ªç±»å‹ä¹‹ä¸‹ï¼Œéœ€è¦é€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°ï¼ˆè¯¯å·®å‡½æ•°ï¼‰æ¥ç¡®å®šå…·ä½“çš„å‚æ•°å€¼ã€‚</p>
<p>å¸¸è§çš„å›å½’æ–¹ç¨‹æœ‰ï¼š</p>
<h3 id="çº¿æ€§å›å½’"><a href="#çº¿æ€§å›å½’" class="headerlink" title="çº¿æ€§å›å½’"></a>çº¿æ€§å›å½’</h3><p>Linear Regressionï¼šå› å˜é‡æ˜¯è¿ç»­çš„ï¼Œè‡ªå˜é‡å¯ä»¥æ˜¯è¿ç»­çš„ä¹Ÿå¯ä»¥æ˜¯ç¦»æ•£çš„ï¼Œå›å½’çº¿çš„æ€§è´¨æ˜¯çº¿æ€§çš„ã€‚</p>
<p>æŸå¤±å‡½æ•° â€“ æœ€å°äºŒä¹˜æ³•ï¼šæœ€å°åŒ–æ¯ä¸ªæ•°æ®ç‚¹åˆ°çº¿çš„å‚ç›´åå·®å¹³æ–¹å’Œæ¥è®¡ç®—æœ€ä½³æ‹Ÿåˆçº¿</p>
<h3 id="é€»è¾‘å›å½’"><a href="#é€»è¾‘å›å½’" class="headerlink" title="é€»è¾‘å›å½’"></a>é€»è¾‘å›å½’</h3><p>Logistic Regressionï¼šå› å˜é‡çš„ç±»å‹å±äºäºŒå…ƒå˜é‡</p>
<p>æŸå¤±å‡½æ•° â€“ æå¤§ä¼¼ç„¶ä¼°è®¡</p>
<p>éœ€è¦å¤§çš„æ ·æœ¬é‡</p>
<h3 id="é€æ­¥å›å½’"><a href="#é€æ­¥å›å½’" class="headerlink" title="é€æ­¥å›å½’"></a>é€æ­¥å›å½’</h3><p>Stepwise Regressionï¼šè‡ªå˜é‡çš„é€‰æ‹©æ˜¯åœ¨ä¸€ä¸ªè‡ªåŠ¨çš„è¿‡ç¨‹ä¸­å®Œæˆçš„</p>
<h3 id="å²­å›å½’"><a href="#å²­å›å½’" class="headerlink" title="å²­å›å½’"></a>å²­å›å½’</h3><p>Ridge Regressionï¼šé€šè¿‡æ”¶ç¼©å‚æ•°Î»ï¼ˆlambdaï¼‰è§£å†³å¤šé‡å…±çº¿æ€§é—®é¢˜ï¼ˆè‡ªå˜é‡é«˜åº¦ç›¸å…³ï¼‰ã€‚å²­å›å½’é€šè¿‡ç»™å›å½’ä¼°è®¡ä¸Šå¢åŠ ä¸€ä¸ªåå·®åº¦ï¼Œæ¥é™ä½æ ‡å‡†è¯¯å·®ã€‚</p>
<p>é™¤å¸¸æ•°é¡¹ä»¥å¤–ï¼Œè¿™ç§å›å½’çš„å‡è®¾ä¸æœ€å°äºŒä¹˜å›å½’ç±»ä¼¼ï¼›å®ƒæ”¶ç¼©äº†ç›¸å…³ç³»æ•°çš„å€¼ï¼Œä½†æ²¡æœ‰è¾¾åˆ°é›¶ï¼Œè¿™è¡¨æ˜å®ƒæ²¡æœ‰ç‰¹å¾é€‰æ‹©åŠŸèƒ½ï¼Œè¿™æ˜¯ä¸€ä¸ªæ­£åˆ™åŒ–æ–¹æ³•ï¼Œå¹¶ä¸”ä½¿ç”¨çš„æ˜¯L2æ­£åˆ™åŒ–ã€‚</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-8b082ec95854efa3bb66dcbbd9be5c36_1440w.jpg" alt="img"></p>
<p>åœ¨è¿™ä¸ªå…¬å¼ä¸­ï¼Œæœ‰ä¸¤ä¸ªç»„æˆéƒ¨åˆ†ã€‚ç¬¬ä¸€ä¸ªæ˜¯æœ€å°äºŒä¹˜é¡¹ï¼Œå¦ä¸€ä¸ªæ˜¯Î²2ï¼ˆÎ²-å¹³æ–¹ï¼‰çš„Î»å€ï¼Œå…¶ä¸­Î²æ˜¯ç›¸å…³ç³»æ•°ã€‚</p>
<h3 id="å¥—ç´¢å›å½’"><a href="#å¥—ç´¢å›å½’" class="headerlink" title="å¥—ç´¢å›å½’"></a>å¥—ç´¢å›å½’</h3><p>Lasso Regressionï¼šä¹Ÿä¼šæƒ©ç½šå›å½’ç³»æ•°çš„ç»å¯¹å€¼å¤§å°ã€‚æ­¤å¤–ï¼Œå®ƒèƒ½å¤Ÿå‡å°‘å˜åŒ–ç¨‹åº¦å¹¶æé«˜çº¿æ€§å›å½’æ¨¡å‹çš„ç²¾åº¦ã€‚</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-c60d9285b983bf247f3dae519e757794_1440w.jpg" alt="img"></p>
<p>Lasso ï¼ˆLeast Absolute Shrinkage and Selection Operatorï¼‰</p>
<h3 id="ElasticNet"><a href="#ElasticNet" class="headerlink" title="ElasticNet"></a>ElasticNet</h3><p>Lassoå’ŒRidgeå›å½’æŠ€æœ¯çš„æ··åˆä½“ã€‚å®ƒä½¿ç”¨L1æ¥è®­ç»ƒå¹¶ä¸”L2ä¼˜å…ˆä½œä¸ºæ­£åˆ™åŒ–çŸ©é˜µã€‚å½“æœ‰å¤šä¸ªç›¸å…³çš„ç‰¹å¾æ—¶ï¼ŒElasticNetæ˜¯å¾ˆæœ‰ç”¨çš„ã€‚Lasso ä¼šéšæœºæŒ‘é€‰ä»–ä»¬å…¶ä¸­çš„ä¸€ä¸ªï¼Œè€ŒElasticNetåˆ™ä¼šé€‰æ‹©ä¸¤ä¸ªã€‚</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-246720018f1a105b08f4501950dd362d_1440w.jpg" alt="img"></p>
<p>Lassoå’ŒRidgeä¹‹é—´çš„å®é™…çš„ä¼˜ç‚¹æ˜¯ï¼Œå®ƒå…è®¸ElasticNetç»§æ‰¿å¾ªç¯çŠ¶æ€ä¸‹Ridgeçš„ä¸€äº›ç¨³å®šæ€§ã€‚</p>
<p><a href="https://zhuanlan.zhihu.com/p/58714364" target="_blank" rel="noopener">å‚è€ƒ</a></p>
<h1 id="åŸºç¡€"><a href="#åŸºç¡€" class="headerlink" title="åŸºç¡€"></a>åŸºç¡€</h1><h2 id="Least-Square-amp-KNN"><a href="#Least-Square-amp-KNN" class="headerlink" title="Least Square &amp; KNN"></a>Least Square &amp; KNN</h2><table>
<thead>
<tr>
<th>Least squares</th>
<th>ğ’Œ-nearest neighbors</th>
</tr>
</thead>
<tbody><tr>
<td>$p$ parameters   ($p$ = #variables)</td>
<td>$\frac N k$ parameters   ($k$: hyperparameter) ($N$ = #observations)</td>
</tr>
<tr>
<td>Low variance (robust)</td>
<td>High variance (not robust)</td>
</tr>
<tr>
<td>High bias (strong assumption)</td>
<td>Low bias (mild assumption)</td>
</tr>
<tr>
<td>Good for Scenario 1: Training data in each class generated from a two-dimensional Gaussian, the two Gaussians are independent and have different means.</td>
<td>Good for Scenario 2: Training data in each class generated from a mixture of 10 low-variance Gaussians, with means again distributed as Gaussian.</td>
</tr>
</tbody></table>
<h2 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h2><p>Squared error loss å¹³æ–¹æŸå¤±å‡½æ•°:<br>$$<br>L(Y,f(x)) = (Y-f(x))^2.<br>$$<br>Expected prediction error (EPE)ï¼šæœŸæœ›é¢„æµ‹è¯¯å·®ï¼Œåœ¨Xå’ŒYçš„å…¨æ¦‚ç‡ç©ºé—´ä¸Šå¯¹æŸå¤±å‡½æ•°æ±‚æœŸæœ›ï¼Œæœ€å°åŒ–EPEå¯ä»¥å¾—åˆ°æœ€å°çš„æŸå¤±ï¼Œå³f(X)æœ€ä¼˜è§£ã€‚</p>
<p>ä½¿ç”¨å¹³æ–¹æŸå¤±å‡½æ•°æ—¶ï¼ŒEPEä¸ºï¼š<br>$$<br>\begin{equation}<br>\begin{aligned}<br>EPE(f) &amp;= E(Y-f(X))^2 \<br>&amp;= \int(y-f(x))^2\Pr(dx,dy) \<br>&amp;=E_XE_{Y|X}([Y-f(X)]^2|X)<br>\end{aligned}<br>\end{equation}<br>$$<br>éœ€è¦å¯»æ‰¾ Regression function: $f(x) = E(Y|X=x)$ ï¼ˆåˆ¤åˆ«æ¨¡å‹ï¼‰</p>
<p>minimize EPE pointwise å¾—åˆ°ï¼š $f(x) = \arg\min_c E_{Y|X}([Y-c]^2|X=x)$ </p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20200525084306848.png" alt="image-20200525084306848"></p>
<p>å¯¹äºKNNæ¥è¯´ï¼Œå®ƒç›´æ¥å¸Œæœ›ç”¨å±€éƒ¨çš„æ ·æœ¬æ•°æ®çš„å¹³å‡æ¥è¿‘ä¼¼æœŸæœ›ï¼š<br>$$<br>\hat{f}(x)={\rm Ave}(y_i|x_i \in N_k(x))<br>$$<br>As $N,k \to \infin $ and $\frac k N \to 0$, we have $\hat{f}(x)={\rm E}(Y|X=x)$ .</p>
<h2 id="ä¸»æˆåˆ†åˆ†æ"><a href="#ä¸»æˆåˆ†åˆ†æ" class="headerlink" title="ä¸»æˆåˆ†åˆ†æ"></a>ä¸»æˆåˆ†åˆ†æ</h2><p>ä¸»æˆåˆ†åˆ†æï¼ˆPrincipal Component Analysisï¼ŒPCAï¼‰æ˜¯ä¸€ç§åœ¨æŸå¤±å¾ˆå°‘ä¿¡æ¯çš„å‰æä¸‹ï¼ŒæŠŠå¤šä¸ªæŒ‡æ ‡è½¬åŒ–ä¸ºå‡ ä¸ªç»¼åˆæŒ‡æ ‡çš„å¤šå…ƒç»Ÿè®¡åˆ†ææ–¹æ³•ï¼Œå®ƒçš„æ ¸å¿ƒæ˜¯<strong>æ•°æ®é™ç»´</strong>æ€æƒ³ï¼Œå³é€šè¿‡é™ç»´çš„æ‰‹æ®µå®ç°å¤šæŒ‡æ ‡å‘ç»¼åˆæŒ‡æ ‡çš„è½¬åŒ–ï¼Œè€Œè½¬åŒ–åçš„ç»¼åˆæŒ‡æ ‡ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºä¸»æˆåˆ†ã€‚</p>
<p>å…¶ä¸­ï¼Œæ¯ä¸ªä¸»æˆåˆ†éƒ½æ˜¯ä¼—å¤šåŸå§‹å˜é‡çš„çº¿æ€§ç»„åˆï¼Œä¸”æ¯ä¸ªä¸»æˆåˆ†ä¹‹é—´äº’ä¸ç›¸å…³ï¼Œè¿™ä½¿å¾—ä¸»æˆåˆ†æ¯”åŸå§‹å˜é‡å…·æœ‰æŸäº›æ›´ä¸ºä¼˜è¶Šçš„æ€§èƒ½ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¦‚æœåŸå§‹æ•°æ®é›†æœ¬èº«è¾ƒä¸ºå¤æ‚ï¼Œé‚£ä¹ˆä½¿ç”¨ä¸»æˆåˆ†åˆ†æå¯ä»¥ä½¿æˆ‘ä»¬ä»…éœ€è¦è€ƒè™‘å‡ ä¸ªç»¼åˆæŒ‡æ ‡ï¼Œè€Œä¸”åˆä¸è‡³äºæŸå¤±å¤ªå¤šä¿¡æ¯ã€‚ä¸€æ–¹é¢ï¼Œå®ƒæ›´å®¹æ˜“å¸®åŠ©æˆ‘ä»¬æŠ“ä½é—®é¢˜çš„ä¸»è¦çŸ›ç›¾ï¼›å¦ä¸€æ–¹é¢ï¼Œå®ƒåˆæå¤§çš„æé«˜äº†æˆ‘ä»¬çš„åˆ†ææ•ˆç‡ã€‚</p>
<p>å‡è®¾æˆ‘ä»¬å¯¹æŸä¸€äº‹ç‰©çš„ç ”ç©¶æ¶‰åŠåˆ°Pä¸ªæŒ‡æ ‡ï¼Œåˆ†åˆ«ç”¨$x_1,x_2,â€¦,x_p$è¡¨ç¤ºï¼Œé‚£ä¹ˆnä¸ªæ ·æœ¬çš„æ•°æ®çŸ©é˜µä¸ºï¼š</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-b3725f2047ca72920ae044775917f9a9_1440w.jpg" alt="img"></p>
<p>æ¥ç€ï¼Œæˆ‘ä»¬å¯¹xè¿›è¡Œçº¿æ€§å˜æ¢ï¼Œå½¢æˆpä¸ªæ–°çš„ç»¼åˆå˜é‡ï¼Œå³æ–°çš„ç»¼åˆå˜é‡å¯ä»¥ç”±åŸå§‹å˜é‡çº¿æ€§è¡¨ç¤ºï¼Œå³ï¼š</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-5a25e7261ddc1d72d221864909bd6e31_1440w.jpg" alt="img"></p>
<p>æ¨¡å‹éœ€è¦æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š</p>
<ol>
<li>$F_i, F_j$ä¹‹é—´äº’ä¸ç›¸å…³</li>
<li>ä»iåˆ°pï¼ŒFçš„æ–¹å·®é€æ¸å‡å°</li>
<li>å„ä¸ªFæ»¡è¶³ç³»æ•°å¹³æ–¹å’Œä¸º1</li>
</ol>
<p>åŸºäºä»¥ä¸Šä¸‰ä¸ªåŸåˆ™ï¼Œå¾—åˆ°çš„ç»¼åˆå˜é‡Fï¼Œåˆ†åˆ«ç§°ä¹‹ä¸ºåŸå§‹å˜é‡çš„ç¬¬ä¸€ï¼Œç¬¬äºŒï¼Œâ€¦ï¼Œç¬¬pä¸ªä¸»æˆåˆ†ã€‚åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸åªæŒ‘é€‰å‰å‡ ä¸ªæ–¹å·®æœ€å¤§çš„ä¸»æˆåˆ†ï¼Œä»è€Œå®ç°æ•°æ®é™ç»´ï¼Œè¾¾åˆ°ç®€åŒ–ç³»ç»Ÿç»“æ„çš„ç›®çš„ã€‚</p>
<h2 id="ç»´æ•°ç¾éš¾"><a href="#ç»´æ•°ç¾éš¾" class="headerlink" title="ç»´æ•°ç¾éš¾"></a>ç»´æ•°ç¾éš¾</h2><p>ç»´æ•°å¢å¤šå¸¦æ¥çš„é«˜ç»´ç©ºé—´æ•°æ®ç¨€ç–åŒ–é—®é¢˜ï¼š</p>
<ul>
<li>åœ¨pç»´ç©ºé—´ï¼ŒNä¸ªç‚¹ä¸¤ä¸¤ä¹‹é—´çš„å¹³å‡è·ç¦»ä¸º$N^{-1/p}$ï¼Œéœ€è¦$N^p$ä¸ªç‚¹æ¥ç»´æŒ1/Nçš„å¹³å‡è·ç¦»ã€‚</li>
<li>Nä¸ªç‚¹åœ¨pç»´å•ä½çƒå†…éšæœºåˆ†å¸ƒï¼Œåˆ™éšç€pçš„å¢å¤§ï¼Œè¿™äº›ç‚¹ä¼šè¶Šæ¥è¶Šè¿œç¦»å•ä½çƒçš„ä¸­å¿ƒï¼Œè½¬è€Œå¾€å¤–ç¼˜åˆ†æ•£ã€‚è¿™ä¸ªå®šç†æºäºå„ç‚¹è·å•ä½çƒä¸­å¿ƒè·ç¦»çš„ä¸­é—´å€¼è®¡ç®—å…¬å¼ï¼š<img src="https://www.zhihu.com/equation?tex=d%28p%2CN%29%3D%281-%5Cfrac%7B1%7D%7B2%7D%5E%7B%5Cfrac%7B1%7D%7BN%7D%7D%29%5E%5Cfrac%7B1%7D%7Bp%7D" alt="å…¬å¼">)å½“pâ†’âˆæ—¶ï¼Œd(p,N)â†’1ã€‚å¾ˆæ˜¾ç„¶ï¼Œå½“Nå˜å¤§æ—¶ï¼Œè¿™ä¸ªè·ç¦»è¶‹è¿‘äº0ã€‚</li>
</ul>
<p>å½“ç»´æ•°å¢å¤§æ—¶ï¼Œç©ºé—´æ•°æ®ä¼šå˜å¾—æ›´ç¨€ç–ï¼Œè¿™å°†å¯¼è‡´biaså’Œvarianceçš„å¢åŠ ï¼Œæœ€åå½±å“æ¨¡å‹çš„é¢„æµ‹æ•ˆæœã€‚</p>
<h2 id="æ–¹å·®-åå·®åˆ†è§£"><a href="#æ–¹å·®-åå·®åˆ†è§£" class="headerlink" title="æ–¹å·®-åå·®åˆ†è§£"></a>æ–¹å·®-åå·®åˆ†è§£</h2><p>bias-variance decomposition</p>
<p>è®­ç»ƒæ•°æ®é›†çš„æŸå¤±ä¸æµ‹è¯•æ•°æ®é›†çš„æŸå¤±ä¹‹é—´çš„å·®å¼‚å°±å«åšæ³›åŒ–è¯¯å·®ï¼ˆgeneralization errorï¼‰ã€‚</p>
<p>æ³›åŒ–è¯¯å·®å¯ä»¥åˆ†è§£ä¸ºï¼š</p>
<p><strong>æ–¹å·®ï¼ˆVarianceï¼‰</strong>ï¼šä½¿ç”¨æ ·æœ¬æ•°ç›¸åŒçš„ä¸åŒè®­ç»ƒé›†äº§ç”Ÿçš„æ–¹å·®ï¼Œå³ä¸åŒçš„è®­ç»ƒæ•°æ®é›†è®­ç»ƒå‡ºçš„æ¨¡å‹è¾“å‡ºå€¼ä¹‹é—´çš„å·®å¼‚ã€‚</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-2a7a3d2a6ec09d77b1171eeee65c8ad5_1440w.jpg" alt="img"></p>
<p>åº¦é‡äº†åŒæ ·å¤§å°çš„è®­ç»ƒé›†çš„å˜åŠ¨ï¼Œæ‰€å¯¼è‡´çš„å­¦ä¹ æ€§èƒ½çš„å˜åŒ–ï¼Œå³åˆ»ç”»äº†æ•°æ®æ‰°åŠ¨æ‰€é€ æˆçš„å½±å“ã€‚</p>
<p><strong>åå·®ï¼ˆBiaseï¼‰</strong>ï¼šæœŸæœ›è¾“å‡ºä¸çœŸå®æ ‡è®°çš„å·®åˆ«ï¼Œå³ç”¨æ‰€æœ‰å¯èƒ½çš„è®­ç»ƒæ•°æ®é›†è®­ç»ƒå‡ºçš„æ‰€æœ‰æ¨¡å‹çš„è¾“å‡ºçš„å¹³å‡å€¼ä¸çœŸå®æ¨¡å‹çš„è¾“å‡ºå€¼ä¹‹é—´çš„å·®å¼‚ã€‚</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-295fb8547dbfcf04cc6127ffb51b9e57_1440w.jpg" alt="img"></p>
<p>åº¦é‡äº†å­¦ä¹ ç®—æ³•çš„æœŸæœ›é¢„æµ‹ä¸çœŸå®ç»“æœçš„åç¦»ç¨‹åº¦ï¼Œå³åˆ»ç”»äº†å­¦ä¹ ç®—æ³•æœ¬èº«çš„æ‹Ÿåˆèƒ½åŠ›ã€‚</p>
<p><strong>å™ªå£°ï¼ˆNoiseï¼‰</strong>ï¼šæ˜¯æ•°æ®é›†æœ¬èº«æ‰€è‡´ï¼Œå­¦ä¹ ç®—æ³•æ— æ³•è§£å†³çš„è¯¯å·®ï¼Œæ•°æ®çš„è´¨é‡å†³å®šäº†å­¦ä¹ çš„ä¸Šé™ï¼Œåœ¨ç»™å®šæ•°æ®é›†çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›æ¥è¿‘è¿™ä¸ªä¸Šçº¿ã€‚</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-b55afb6e8136fae9055e8ba7a6f12ba7_1440w.jpg" alt="img"></p>
<p>è¡¨è¾¾äº†åœ¨å½“å‰ä»»åŠ¡ä¸Šä»»ä½•å­¦ä¹ ç®—æ³•æ‰€èƒ½è¾¾åˆ°çš„æœŸæœ›æ³›åŒ–è¯¯å·®çš„ä¸‹ç•Œï¼Œå³åˆ»ç”»äº†å­¦ä¹ é—®é¢˜æœ¬èº«çš„éš¾åº¦ã€‚</p>
<p>åå·®åº¦é‡çš„æ˜¯å•ä¸ªæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ï¼Œè€Œæ–¹å·®åº¦é‡çš„æ˜¯åŒä¸€ä¸ªæ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„ç¨³å®šæ€§ã€‚</p>
<p><strong>åˆ†è§£è¿‡ç¨‹</strong>ï¼ˆå‡å®šå™ªå£°æœŸæœ›ä¸ºé›¶ï¼‰ï¼š</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-0751754b1ace1d4741e474d4d1abe51c_1440w.jpg" alt="img"></p>
<p>äºæ˜¯ï¼Œæœ€ç»ˆå¾—åˆ°ï¼š</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-69a3c3949b21f1c016dbb01780ebdeca_1440w.jpg" alt="img"></p>
<p>æ³›åŒ–æ€§èƒ½æ˜¯ç”±å­¦ä¹ ç®—æ³•çš„èƒ½åŠ›ã€æ•°æ®çš„å……åˆ†æ€§ä»¥åŠå­¦ä¹ ä»»åŠ¡æœ¬èº«çš„éš¾åº¦æ‰€å…±åŒå†³å®šçš„ã€‚ç»™å®šå­¦ä¹ ä»»åŠ¡ï¼Œä¸ºäº†å–å¾—å¥½çš„æ³›åŒ–æ€§èƒ½ï¼Œåˆ™éœ€ä½¿åå·®è¾ƒå°ï¼Œå³èƒ½å¤Ÿå……åˆ†æ‹Ÿåˆæ•°æ®ï¼Œå¹¶ä¸”ä½¿æ–¹å·®è¾ƒå°ï¼Œå³ä½¿å¾—æ•°æ®æ‰°åŠ¨äº§ç”Ÿçš„å½±å“å°ã€‚</p>
<p><a href="https://zhuanlan.zhihu.com/p/38853908" target="_blank" rel="noopener">å‚è€ƒ</a></p>
<h2 id="æ¦‚ç‡ä¼°è®¡"><a href="#æ¦‚ç‡ä¼°è®¡" class="headerlink" title="æ¦‚ç‡ä¼°è®¡"></a>æ¦‚ç‡ä¼°è®¡</h2><p>æˆ‘ä»¬å¯ä»¥é€šè¿‡æ±‚è§£æ¦‚ç‡å‡½æ•°$P(Y|X)$æ¥ä¼°è®¡$f:X\to Y$ï¼Œè‹¥å·²çŸ¥æ‰€æœ‰ RV çš„ joint distributionï¼Œå¾ˆå®¹æ˜“å¯ä»¥ç®—å‡ºæ¦‚ç‡å‡½æ•°çš„æ•°å€¼è§£ï¼Œä½†æ˜¯é€šå¸¸æƒ…å†µéœ€è¦çš„æ ·æœ¬å¤ªå¤§ï¼Œåªèƒ½é€šè¿‡å…¶ä»–æ–¹æ³•æ¥ä¼°è®¡$f:X\to Y$ </p>
<ol>
<li>be smart about how we estimate probability parameters from available data: MLE, MAP</li>
<li>be smart about how we represent joint probability distributions: NaÃ¯ve Bayes, Bayes Nets</li>
</ol>
<h3 id="MLE"><a href="#MLE" class="headerlink" title="MLE"></a>MLE</h3><p>Maximum Likelihood Estimation</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20200419161827133.png" alt="MLE"></p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20200419162041583.png" alt="MLE2"></p>
<p>é€šå¸¸ç”¨$\ell (\theta)$è¡¨ç¤º$lnP(D|\theta)$ï¼Œç”¨$L(\theta)$è¡¨ç¤ºä¼¼ç„¶å‡½æ•°$P(D|\theta)$ </p>
<p>é€ç‚¹æœ€å°åŒ–ï¼š</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20200419162526934.png" alt="image-20200419162526934"></p>
<p>å¯å¾—åˆ°æ‰€éœ€å‚æ•°$\theta$ </p>
<h3 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a>MAP</h3><p>Maximum a Posteriori Probability Estimation</p>
<p>è¿™æ˜¯è´å¶æ–¯çš„æ–¹æ³•ï¼Œé€šè¿‡æœ€å¤§åŒ–åéªŒæ¦‚ç‡ï¼Œæ¥ä½¿å¾—å‚æ•°ä¼°è®¡å¯ä»¥å®¹çº³å…ˆéªŒå‡è®¾$P(\theta)$ï¼Œå…¶ä½™å’ŒMLEç›¸åŒ</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20200419162750421.png" alt="image-20200419162750421"></p>
<p>$P(\theta)$ä¸$\theta$æ— å…³ï¼Œåªèµ·åˆ°å½’ä¸€åŒ–ä½œç”¨ï¼Œæ‰€ä»¥ä¸€èˆ¬å¿½ç•¥ä¸ºï¼š</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20200419162923462.png" alt="image-20200419162923462"></p>
<p>å…¶ä¸­å…ˆéªŒæ¦‚ç‡æœªçŸ¥ï¼Œå…¶ä»–éƒ½å¯ä»¥è¡¨ç¤ºï¼Œä¸€ç§å¯¹è´å¶æ–¯ä¼°è®¡çš„æ‰¹åˆ¤å°±æ˜¯äººä»¬é€šå¸¸ä¸ºäº†ç®€åŒ–è®¡ç®—é€‰æ‹©å…ˆéªŒæ¦‚ç‡ï¼Œæ­¤å¤„æˆ‘ä»¬å¯ä»¥é€‰æ‹©Beta distributionï¼š</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20200419163110416.png" alt="image-20200419163110416"></p>
<p>ï¼ˆå‚è€ƒML version2 chapter2 Estimating Probabilitiesï¼‰</p>
<p>ç”¨è¿™ä¸¤ç§æ–¹æ³•ä¼°è®¡ä¼¯åŠªåˆ©åˆ†å¸ƒ</p>
<h1 id="æ¦‚ç‡å›¾æ¨¡å‹"><a href="#æ¦‚ç‡å›¾æ¨¡å‹" class="headerlink" title="æ¦‚ç‡å›¾æ¨¡å‹"></a>æ¦‚ç‡å›¾æ¨¡å‹</h1><p><a href="http://www.cs.cmu.edu/~epxing/Class/10708-14/lecture.html" target="_blank" rel="noopener">CMU PGM</a></p>
<p>Graphical Models ç»™å‡ºäº†å˜é‡ä¹‹é—´å…³è”æ€§çš„å…ˆéªŒçŸ¥è¯†ä»¥åŠå‚æ•°ä¼°è®¡ï¼ˆMAPï¼‰çš„å…ˆéªŒçŸ¥è¯†ï¼›è”ç³»è§‚æµ‹åˆ°çš„è®­ç»ƒæ•°æ®ï¼Œè¿›è¡Œä¼°è®¡&amp;å­¦ä¹ ï¼ˆå¸¸ç”¨äºï¼šDiagnosis, help systems, text analysis, time series models, â€¦ï¼‰</p>
<p><strong>æ ¸å¿ƒé—®é¢˜</strong>ï¼šå¤„ç†é«˜ç»´éšæœºå˜é‡ $p(x_1,x_2,â€¦,x_p)$ </p>
<p><strong>åˆ†ç±»</strong>ï¼š</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-714c1843f78b6aecdb0c57cdd08e1c6a_1440w.jpg" alt="img"></p>
<ul>
<li>æœ‰å‘å›¾ aka Bayesian Networks</li>
<li>æ— å‘å›¾ aka Markov Random Fields</li>
</ul>
<p>ä¸ºäº†è§£å†³é«˜ç»´éšæœºå˜é‡è®¡ç®—é‡å·¨å¤§çš„é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®ä¸åŒæ¦‚ç‡å›¾è¡¨ç¤ºçš„å…³ç³»ç®€åŒ–$p(x_1,x_2,â€¦,x_p)$ </p>
<p><strong>åŸºæœ¬æ³•åˆ™</strong>ï¼š</p>
<ul>
<li>Conditional Independenceï¼šä¹˜æ³•$P(X|Y,Z)=P(X|Z)$ </li>
<li>Marginal Independenceï¼šåŠ æ³•/ç§¯åˆ†$P(X,Y)=P(X)P(Y)$ </li>
</ul>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-1f99b4cbadaa82866ea4baa3118b8323_720w.png" alt="img"></p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-563d4852cc96f327d98a575c1b4acea7_720w.png" alt="img"></p>
<p>å¯æ¨å‡ºä¸¤ä¸ªå¸¸ç”¨æ³•åˆ™ï¼šé“¾å¼æ³•åˆ™ï¼›è´å¶æ–¯æ³•åˆ™</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-34f4356a1735f2797818be6dde57676b_720w.png" alt="img"></p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-e86a7c08e96c0fb7d2b964a45bbd5e4c_720w.png" alt="img"></p>
<h2 id="Naive-Bayes"><a href="#Naive-Bayes" class="headerlink" title="NaÃ¯ve Bayes"></a>NaÃ¯ve Bayes</h2><p>å…¶å®ä¸ç®—PGMï¼Œéå¸¸naÃ¯veçš„ä¸€ä¸ªå‡è®¾ï¼šæ‰€æœ‰ç»´åº¦ç›¸äº’ç‹¬ç«‹ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥å±•å¼€ï¼š</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-6bd6eb3a5df5f155db6a655296814147_720w.png" alt="img"></p>
<p>ç›¸å¯¹äºNaÃ¯ve Bayesçš„é“¾å¼æ³•åˆ™çš„å±•å¼€ï¼ŒBNæ›´åŠ çµæ´»çš„è¡¨ç¤ºäº†æ¡ä»¶ç‹¬ç«‹å…³ç³»ï¼Œå¯ä»¥è¡¨ç¤ºé›†åˆä¹‹é—´çš„ç‹¬ç«‹å…³ç³»ï¼Œå¹¶ä¸”å¤§å¤§å‡å°‘äº†ç‹¬ç«‹å‚æ•°çš„ä¸ªæ•°ï¼Œä»æŒ‡æ•°çº§é™åˆ°äº†çº¿æ€§</p>
<p>å±äºç”Ÿæˆæ¨¡å‹</p>
<h2 id="Bayesian-Networks"><a href="#Bayesian-Networks" class="headerlink" title="Bayesian Networks"></a>Bayesian Networks</h2><h3 id="Representation"><a href="#Representation" class="headerlink" title="Representation"></a>Representation</h3><p>BNåŒ…æ‹¬ï¼š</p>
<ul>
<li>DAGï¼š$G=&lt;V,E&gt;$ </li>
<li>CPD/CPTï¼š$P(X_i|Pa(X_i))$ </li>
</ul>
<p>Vä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹å…³ç³»å¯ç”±D-separatedå’ŒMarkov Blanketè¡¨è¿°</p>
<p>Terminology:</p>
<ul>
<li>Parents = Pa(X) = immediate parents</li>
<li>Antecedents = An(X) = parents, parents of parents, â€¦</li>
<li>Children = Ch(X) = immediate children</li>
<li>Descendents = De(X) = children, children of children, â€¦</li>
</ul>
<p>åˆ†ç±»ï¼š</p>
<ul>
<li>é™æ€è´å¶æ–¯ç½‘ç»œï¼šç®€ç®€å•å•çš„æ ¹æ®DAGåˆ†è§£é«˜ç»´éšæœºå˜é‡å°±è¡Œ</li>
<li>åŠ¨æ€è´å¶æ–¯ç½‘ç»œ DBNï¼šåŒ…æ‹¬HMMå’ŒKalman filters</li>
</ul>
<p>Hidden Markov Modelæ˜¯é’ˆå¯¹æ—¶åºåˆ†æçš„ä¸€ç§æ–¹æ³•time seriesï¼ŒRNNä¹Ÿæ˜¯é’ˆå¯¹æ—¶åºåˆ†æçš„ï¼ˆéœ€è¦æ›´å¤šæ•°æ®ï¼Œåˆ†ç±»ç²¾åº¦æ›´é«˜ï¼‰</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/HMM.png" alt="Screen Shot 2020-04-28 at 7.43.37 AM"></p>
<h4 id="D-separated"><a href="#D-separated" class="headerlink" title="D-separated"></a>D-separated</h4><p>ä½œç”¨ï¼šä»å›¾ä¸­æ‰¾åˆ°æ¡ä»¶ç‹¬ç«‹å…³ç³»ï¼Œç®€åŒ–è®¡ç®—</p>
<p>ä¸‰ç§åŸºæœ¬æ‹“æ‰‘ç»“æ„ï¼š</p>
<ul>
<li>H-Tå’ŒT-Tï¼šè§‚æµ‹åˆ°Cæ—¶ï¼ŒAä¸Bä¹‹é—´é€šé“é˜»å¡ï¼ŒAä¸Bç‹¬ç«‹ï¼›æœªè§‚æµ‹åˆ°Cæ—¶ï¼ŒAä¸Bå¯é€šè¿‡Cå»ºç«‹æŸç§è”ç³»ï¼ŒAä¸Bæ— marginal independentï¼ˆ$A \perp B |C$ &amp; $A \not\perp B$  ï¼‰</li>
<li>H-Hï¼šè§‚æµ‹åˆ°Cæ—¶ï¼ŒAä¸Båè€Œå—åˆ°è”ç³»ï¼Œä¸å†ç‹¬ç«‹ï¼›å¦åˆ™æ˜¯marginal independentçš„ï¼ˆ$A \not\perp B |C$ &amp; $A \perp B$  ï¼‰â€”â€”explaining away</li>
</ul>
<p>D-separated å…¶å®å°±æ˜¯ä¸‰ç§åŸºæœ¬æ‹“æ‰‘èŠ‚ç‚¹å…³ç³»çš„ä¸€ä¸ªæ¨å¹¿ï¼Œå°†èŠ‚ç‚¹å…³ç³»æ¨å¹¿åˆ°é›†åˆå…³ç³»ã€‚å‡å®šé›†åˆABCç›¸äº’ä¹‹é—´ä¸ç›¸äº¤ï¼Œè‹¥åœ¨Aå’ŒCä¹‹é—´å­˜åœ¨è·¯å¾„èŠ‚ç‚¹bï¼ŒèŠ‚ç‚¹bå’Œé›†åˆBä¹‹é—´æ»¡è¶³å…³ç³»ï¼š</p>
<ol>
<li>å½“bèŠ‚ç‚¹çš„æ‹“æ‰‘å…³ç³»ä¸ºtailâ€”tail, headâ€”tailè¿™ä¸¤ç§ç±»å‹æ˜¯ï¼Œ$b\in B$ </li>
<li>å½“bèŠ‚ç‚¹çš„æ‹“æ‰‘å…³ç³»ä¸ºheadâ€”headç»“æ„æ—¶ï¼ŒbèŠ‚ç‚¹åŠå…¶<u>åç»§èŠ‚ç‚¹</u>ä¸€å®šä¸åœ¨Bé›†åˆå½“ä¸­ï¼Œ$b \not\in B$ </li>
</ol>
<p>åˆ™$A \perp C |B$ </p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/image-20200428154248188.png" alt="image-20200428154248188"></p>
<p>å¯ä»¥ç”¨é©¬å°”ç§‘å¤«æ¯¯æ¥è¡¨ç¤ºè¿™ç§å…³ç³»</p>
<h4 id="Markov-Blanket"><a href="#Markov-Blanket" class="headerlink" title="Markov Blanket"></a>Markov Blanket</h4><p>æ¦‚ç‡å›¾ä¸­ï¼Œä¸ºäº†ä½¿å…¶ä¸­ä¸€ä¸ªèŠ‚ç‚¹å’Œå…¶å®ƒèŠ‚ç‚¹æ¡ä»¶ç‹¬ç«‹ï¼Œæˆ‘ä»¬ç”¨æ¯¯å­ç›–ä½è¿™ä¸ªèŠ‚ç‚¹å‘¨å›´ä¸å…¶ç›¸å…³çš„èŠ‚ç‚¹ï¼Œé‚£ä¹ˆæ¯¯å­å¤–é¢çš„èŠ‚ç‚¹å’Œè¿™ä¸ªèŠ‚ç‚¹å°±æ¡ä»¶ç‹¬ç«‹äº†ã€‚</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/MB.png" alt="Screen Shot 2020-04-28 at 11.11.58 AM"></p>
<p>åœ¨åŸºäºå…¨å±€èŠ‚ç‚¹æ¡ä»¶ä¸‹ï¼Œæ±‚æŸä¸€ä¸ªèŠ‚ç‚¹çš„æ¦‚ç‡é—®é¢˜å¯ä»¥å†™ä¸ºï¼š<br>$$<br>p(x_i|x_{-i}) \propto \frac{p(x_i|x_{pa(i)})}{p(x_{ch(i)}|x_i,x_{pa(ch(i))})}<br>$$</p>
<h4 id="Markov-Random-Fields"><a href="#Markov-Random-Fields" class="headerlink" title="Markov Random Fields"></a>Markov Random Fields</h4><p>é©¬å°”å¯å¤«ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨åŠ¿èƒ½ ï¼ˆ$\phi_i$ï¼‰æ¥è¡¨ç¤ºä¸åŒç»“ç‚¹æˆ–ç»“ç‚¹å›¢ä¹‹é—´çš„å½±å“åŠ›å¤§å°ã€‚</p>
<p>å¯ä»¥ç”¨è”åˆåˆ†å¸ƒï¼ˆGibbsåˆ†å¸ƒï¼‰è¡¨ç¤ºé©¬å°”å¯å¤«ç½‘ç»œ</p>
<p><img src="%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/v2-9989dbc8e5ddbf84c19f1b57ecd80805_1440w.jpg" alt="img"></p>
<p>né˜¶é©¬å°”å¯å¤«å‡è®¾ï¼ˆHMMæ˜¯1-gramï¼‰ä¸‹çš„é©¬å°”å¯å¤«è¿‡ç¨‹ï¼šåœ¨ä¸€ä¸ªè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªçŠ¶æ€çš„è½¬ç§»åªä¾èµ–äºå‰nä¸ªçŠ¶æ€ï¼Œå¹¶ä¸”åªæ˜¯ä¸ªné˜¶çš„æ¨¡å‹ã€‚</p>
<h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p>è¦æ˜¯èƒ½çŸ¥é“CPDï¼Œå¸¦å…¥å°±å¥½äº†</p>
<p>NP-hardé—®é¢˜</p>
<p>Approximate methods too, e.g., Monte Carlo methods, â€¦</p>
<p>P14</p>
<h3 id="Learning"><a href="#Learning" class="headerlink" title="Learning"></a>Learning</h3><p>Given training set Dï¼Œfind CPD</p>
<p>å¯¹äºæ¯ä¸ªnode iï¼š</p>
<ul>
<li>ç¡®å®š$Pa(X_i)$æ¥è®¾å®šCPDä¸­å¾…å­¦ä¹ å‚æ•°</li>
<li>æ‰¾åˆ°è¯¥èŠ‚ç‚¹çš„æ¦‚ç‡å¯†åº¦å‡½æ•°å’Œå¯¹åº”çš„ä¼¼ç„¶å‡½æ•°</li>
<li>é€ç‚¹æœ€å°åŒ–$L(\theta)$æ±‚å¾—å‚æ•°</li>
</ul>
<p>HW3.3</p>
<ul>
<li>Easy for known graph, fully observed data (MLEâ€™s, MAP est.)</li>
<li><strong>EM</strong> for partly observed data, known graph</li>
<li>Learning graph structure: <strong>Chow-Liu</strong> for tree-structured networks</li>
<li>Hardest when graph unknown, data incompletely observed</li>
</ul>
<h4 id="EMç®—æ³•"><a href="#EMç®—æ³•" class="headerlink" title="EMç®—æ³•"></a>EMç®—æ³•</h4><p>Expectation - Maximizationï¼šæ˜¯ä¸ºäº†åœ¨æ¦‚ç‡å›¾å·²çŸ¥ï¼Œæ•°æ®æœªçŸ¥æˆ–è€…éƒ¨åˆ†æœªçŸ¥çš„æƒ…å†µä¸‹åº”ç”¨bayesçš„ç®—æ³•</p>
<ul>
<li>åˆå§‹åŒ– theta</li>
<li>E-stepï¼šç”¨ $X$ å’Œ $\theta$ï¼Œè®¡ç®— $P(X,Z|\theta â€˜)$ </li>
<li>M-stepï¼šæ›´æ–°thetaï¼š$\theta \to \arg\max\limits_{\theta â€˜} Q(\theta â€˜|\theta)$ ï¼‰<ul>
<li>å¯¹äºMLEæ¥è¯´ï¼š$Q(\theta â€˜|\theta) = E_{P(Z|X,\theta)}[\log P(X,Z|\thetaâ€™)]$ </li>
</ul>
</li>
</ul>
<p>Usupervised clustering is just extreme case for EM with zero labeled examples</p>
<p>EM for Mixture of Gaussian Clusteringï¼šLec11&amp;12P21</p>
<h4 id="Chow-Liuç®—æ³•"><a href="#Chow-Liuç®—æ³•" class="headerlink" title="Chow-Liuç®—æ³•"></a>Chow-Liuç®—æ³•</h4><p>å¦‚ä½•æ„å»ºæ¦‚ç‡å›¾ï¼Ÿ</p>
<p>Chow-Liu Algorithmï¼šminimizes Kullback-Leibler divergenceï¼Œto finds â€œbestâ€ tree-structured network<br>$$<br>KL(P(X)||T(X)) \equiv \sum_k P(X=k)\log \frac{P(X=k)}{T(X=k)}<br>$$<br>To minimize $KL(P || T)$ , it suffices to find the tree network T that maximizes the sum of mutual informations $I(A,B)$ over its edges (like between variable A and B)<br>$$<br>I(A,B) = \sum_a \sum_b P(a,b) \log \frac{P(a,b)}{P(a)P(b)}<br>$$<br>for tree networks with nodes $X \equiv &lt;X_1,â€¦,X_n&gt;$<br>$$<br>\begin{equation}<br>\begin{aligned}<br>KL(P(X)||T(X)) &amp;\equiv \sum_k P(X=k)\log \frac{P(X=k)}{T(X=k)} \&amp;= -\sum_i I(X_i,Pa(X_i)) + \sum_i H(X_i) - H(X_1 â€¦ X_n))<br>\end{aligned}<br>\end{equation}<br>$$</p>
<ol>
<li>for each pair of vars $A,B$, use data to estimate $P(A,B), P(A), P(B)$ </li>
<li>for each pair of vars $A,B$ calculate mutual information $I(A,B)$ </li>
<li>calculate the <em>maximum spanning tree</em> over the set of variables, using edge weights $I(A,B)$  (given $N$ vars, this costs only $O(N^2)$ time)</li>
<li>add arrows to edges to form a directed-acyclic graph</li>
<li>learn the CPDâ€™s for this graph</li>
</ol>
<h1 id="å­¦ä¹ ç†è®º"><a href="#å­¦ä¹ ç†è®º" class="headerlink" title="å­¦ä¹ ç†è®º"></a>å­¦ä¹ ç†è®º</h1><p>Computational Learning Theory</p>
<p>ï¼ˆML 7.1-7.4ï¼›æ—è½©ç”°MLFï¼›è¥¿ç“œ 12ï¼‰</p>
<p>æ˜¯ä¸€ä¸ªâ€œå¯è®¡ç®—ä¸å¤æ‚åº¦ç†è®ºâ€å’Œâ€œæœºå™¨å­¦ä¹ â€çš„äº¤å‰å­¦ç§‘ï¼Œå¯ä»¥çœ‹åšæ˜¯ç”¨ç®—æ³•åˆ†æçš„å¥—è·¯æ¥åˆ†ææœºå™¨å­¦ä¹ æ¨¡å‹å’Œé—®é¢˜ã€‚ç”¨æ¦‚ç‡å’Œç»„åˆæ•°å­¦çš„æ–¹æ³•åœ¨æŸæŸé™åˆ¶ä¸‹è¯æ˜æŸæŸçš„ä¸Šä¸‹é™åˆ†åˆ«æ˜¯å¤šå°‘</p>
<p>å›ç­”äº†æ˜¯å¦å¯ä»¥ä»æ•°æ®ä¸­æ‹Ÿåˆåˆ°çœŸå®çš„functionï¼›ä¹Ÿå¯ä»¥ç”±æ­¤å‘å±•å‡ºæ–°çš„ç®—æ³•</p>
<ul>
<li>statistical learning theoryï¼ˆSLTï¼‰</li>
<li>probably approximately correctï¼ˆPACï¼‰</li>
</ul>
<p>æˆ‘ä»¬å¸Œæœ› h has small error over Dï¼Œä½†æ˜¯ $err_D(h)$ ä¸å¯æµ‹é‡ï¼ˆdistributionæœªçŸ¥ï¼‰ï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥æ‰¾åˆ°å®ƒçš„ä¸Šé™ã€‚æˆ‘ä»¬å¯ä»¥è®¡ç®—çš„æ˜¯è®­ç»ƒè¯¯å·® $err_S(h)$ï¼Œæ‰€ä»¥å¸Œæœ›ç”¨training erroræè¿°testing errorçš„upper boundï¼š</p>
<p>TRUE errorï¼ˆgeneralization errorï¼‰ï¼š$err_D(h) = \Pr(h(x)\not=c^*(x))$ï¼Œå°±æ˜¯ä¸ç›¸ç­‰çš„æœŸæœ›ï¼ˆ0,1 lossçš„æƒ…å†µä¸‹ï¼‰å¯¹äºæ•´ä¸ªdistributionæ¥è¯´çš„åˆ†ç±»é”™è¯¯ç‡</p>
<p>Training errorï¼ˆEmpirical errorï¼‰ï¼š$err_S(h)=\frac 1 m \sum_i I(h(x_i)\not = c^*(x_i))$ ï¼Œå¯¹äºè®­ç»ƒæ•°æ®æ¥è¯´çš„åˆ†ç±»é”™è¯¯ç‡ã€‚</p>
<p>ä¸¤ç§æƒ…å†µï¼š</p>
<ul>
<li>$c^* \in H$ ï¼šRealizable</li>
<li>$c^* \not\in H$ ï¼šAgnostic learningï¼ˆæ‰¾åˆ°h close to c*ï¼‰</li>
</ul>
<p><strong>Consistent Learner</strong>ï¼š$h(x)=c^*(x),\quad \forall x\in S.$ </p>
<p><strong>Version Space (VS)</strong>ï¼š$VS_{H,S}={h\in H|h(x)=c^*(x), \forall x\in S.}$ </p>
<p><strong>$\epsilon$-exhausted</strong>ï¼š$VS_{H,S}$ è¢«ç§°ä¸º $\epsilon$-exhausteï¼Œå¦‚æœ $(\forall h\in VS_{H,S})err_D(h)&lt;\epsilon$ </p>
<h2 id="PAC-learning"><a href="#PAC-learning" class="headerlink" title="PAC learning"></a>PAC learning</h2><p><strong>PAC Identify</strong>ï¼šè‹¥å¯¹äºè¯¯å·® $\epsilon&gt;0$ï¼Œç½®ä¿¡åº¦ $\delta&lt;1$ï¼Œæ‰€æœ‰çœŸå®å‡½æ•° $c\in C$ å’Œåˆ†å¸ƒ $D$ï¼Œå­˜åœ¨å­¦ä¹ ç®—æ³• $L$ï¼Œå…¶è¾“å‡ºå‡è®¾ $h\in H$ æ»¡è¶³ $P(E(h)\le \epsilon)\ge 1-\delta$ï¼Œåˆ™ç§° $L$ èƒ½ä»å‡è®¾ç©ºé—´ $H$ ä¸­ PAC Identify $C$  </p>
<p><strong>PAC Learnable</strong>ï¼šè‹¥å¯¹äºä»»ä½•ä»åˆ†å¸ƒ $D$ ä¸­ $iid$ é‡‡æ ·å¾—åˆ°çš„è®­ç»ƒæ ·æœ¬é›†åˆ $m$ï¼Œ$m$ æ»¡è¶³ $m\ge {\rm poly}(1/\epsilon,1/\delta,size(\textbf x),size(c))$ ï¼Œéƒ½æœ‰ $L$ èƒ½PAC Identify $C$ï¼Œåˆ™ç§° $C$ (å¯¹äº$H$)æ˜¯PAC Learnable çš„.</p>
<h2 id="VC-dimension"><a href="#VC-dimension" class="headerlink" title="VC dimension"></a>VC dimension</h2><p>VC dimension æè¿°äº†å‡è®¾ç©ºé—´çš„å¤æ‚åº¦</p>
<p><strong>Growth function</strong>ï¼šå¢é•¿å‡½æ•°è¡¨ç¤ºå‡è®¾ç©ºé—´ $H$ å¯¹ $m$ ä¸ªç¤ºä¾‹æ‰€èƒ½èµ‹äºˆæ ‡è®°çš„æœ€å¤§å¯èƒ½ç»“æœæ•°ã€‚$\prod_H(m)$ ä¸ºå‡è®¾ç©ºé—´åœ¨æ•°æ®é›†å¤§å°ä¸ºmæ—¶çš„å¢é•¿å‡½æ•°ã€‚</p>
<p><strong>dichotomy</strong>ï¼šå¯¹äºäºŒåˆ†ç±»é—®é¢˜æ¥è¯´ï¼Œ$H$ ä¸­çš„å‡è®¾å¯¹ $D$ ä¸­ $m$ ä¸ªç¤ºä¾‹èµ‹äºˆæ ‡è®°çš„æ¯ç§å¯èƒ½ç»“æœç§°ä¸ºå¯¹$D$ çš„ä¸€ç§å¯¹åˆ†</p>
<p><strong>shattering</strong>ï¼šè‹¥å‡è®¾ç©ºé—´ $H$ èƒ½å®ç°æ•°æ®é›† $D$ ä¸Šçš„æ‰€æœ‰å¯¹åˆ†ï¼Œåˆ™ç§° $D$ èƒ½è¢« $H$ æ‰“æ•£</p>
<p><strong>VC dimension</strong>ï¼šå‡è®¾ç©ºé—´ $H$ çš„VCç»´æ˜¯èƒ½è¢« $H$ æ‰“æ•£çš„æœ€å¤§çš„æ•°æ®é›†å¤§å°ï¼š$VC(H)=max{m:\prod_H(m)=2^m}$ã€‚ä¸æ•°æ®åˆ†å¸ƒæ— å…³ã€‚</p>
<p>growth functionå’Œvc dimç´§å¯†ç›¸å…³ï¼Œå¯ä»¥å¾—åˆ°ç»™äºˆVC dimçš„æ³›åŒ–è¯¯å·®ä¸Šé™</p>
<p><strong>Rademacher complexity</strong>ï¼šå¦ä¸€ç§åˆ»ç”»å‡è®¾ç©ºé—´å¤æ‚åº¦çš„æ–¹æ³•ï¼Œä¸ VC dimä¸åŒçš„æ˜¯ï¼Œå®ƒåœ¨ä¸€å®šç¨‹åº¦ä¸Šè€ƒè™‘äº†æ•°æ®åˆ†å¸ƒï¼Œæ‰€ä»¥é€šå¸¸æ¯”åŸºäº VC dim çš„å¤æ‚åº¦æ›´ç´§ä¸€ç‚¹</p>
<p><strong>Stability</strong>ï¼šæˆ‘ä»¬è¿˜å¯ä»¥è€ƒè™‘ç®—æ³•çš„ç¨³å®šæ€§ï¼Œå³ç®—æ³•åœ¨è¾“å…¥å‘ç”Ÿå˜åŒ–æ—¶ï¼Œè¾“å‡ºçš„å˜åŒ–ç¨‹åº¦</p>
<h1 id="é›†æˆå­¦ä¹ "><a href="#é›†æˆå­¦ä¹ " class="headerlink" title="é›†æˆå­¦ä¹ "></a>é›†æˆå­¦ä¹ </h1><p>[all from Robert E. Schapire, 2001, boosting survey]</p>
<p>Boostingï¼šæé«˜ä»»ä½•å­¦ä¹ ç®—æ³•æ­£ç¡®ç‡çš„é€šç”¨æ–¹æ³•</p>
<ul>
<li>find a base learner (or weak leaner)</li>
<li>æ¯ä¸€è½®ï¼Œç”¨æ­¤learnerå­¦ä¹ training examples with different distribution or weightingã€‚ç„¶åæ›´æ–° distribution â€”â€” å¦‚ä½•æ›´æ–°ï¼Ÿ</li>
<li>æœ€å combine æ¯ä¸€è½®çš„weak learner into a single strong learner â€”â€” å¦‚ä½•combineï¼Ÿ</li>
</ul>
<p>å¦‚ä½•combineï¼šä¸€èˆ¬æ¥è¯´å°±ç”¨å¤šæ•°æŠ•ç¥¨çš„æ–¹æ³•ã€‚As for combining the weak rules, simply taking a (weighted) majority vote of their predictions is natural and effective.</p>
<hr>
<p><strong>The boosting algorithm AdaBoost</strong> </p>
<p>Given: $(x_1,y_1),â€¦,(x_m,y_m)$ where $x_i \in X, y_i \in Y = {-1,+1}$ </p>
<p>Initialize $D_1(i)=1/m$.<br>For $t=1,â€¦,T$ : </p>
<ul>
<li>Train base learner using distribution $D_t$.</li>
<li>Get base classifier $h_t:X\to \mathbb{R}$ for distribution $D_t$.</li>
<li>Choose $\alpha_t \in \mathbb{R}$ .</li>
<li>Update: $D_{t+1}(i)=\frac{D_t(i)}{Z_t}\exp[-\alpha_t y_i h_t (x_i)]$ where $Z_t$ is a normalization factor (chosen so that $D_{t+1}$ will be a distribution), and $y_i h_t (x_i)$ is an indicator.</li>
</ul>
<p>Output the final classifier:<br>$$<br>H(x)=sign(f(x))=sign(\sum_{t=1}^{T}\alpha_t h_t(x))<br>$$</p>
<hr>
<p><strong>Training error</strong></p>
<p>æ›´æ–° $D_t$ çš„æ³•åˆ™æ˜¯æœ€å°åŒ– training error</p>
<p>è®­ç»ƒè¯¯å·®çš„ä¸Šé™ç”±Freund and Schapireç»™å‡ºï¼š<br>$$<br>\frac1m |{i:H(x_i)}\not= y_i| \le \frac1m \sum_i \exp(-y_i f(x_i)) = \prod_t Z_t<br>$$<br>Proof: Lec15 P22-27</p>
<p>è®­ç»ƒè¯¯å·®ä¸Šé™éšç€ t çš„å¢åŠ ï¼Œé€æ¸å»¶ä¼¸ï¼Œå¹¶ä¸”ä¸æ–­å‡å°</p>
<p>æ‰€ä»¥ä¸ºäº†å‡å°è®­ç»ƒè¯¯å·® in a greedy wayï¼Œæˆ‘ä»¬éœ€è¦æœ€å°åŒ–ï¼š<br>$$<br>Z_t =\sum_i D_t(i) \exp(-y_i f(x_i))<br>$$<br>ä»è€Œï¼Œå¯¹äºbinary classifiersï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ï¼š<br>$$<br>\alpha_t = \frac12 ln(\frac{1-\epsilon_t}{\epsilon_t})<br>$$<br>å¹¶ä¸”ï¼Œæ­¤æ—¶è®­ç»ƒè¯¯å·®ä¸Šé™ä¸º $\exp(-2\sum_t \gamma_t^2)$ï¼Œå…¶ä¸­ $\gamma_t = 1/2-\epsilon_t$ </p>
<p>å› ä¸ºè¯¥ä¸Šé™æœ€å¤§å€¼ä¸º $e^{-2T\gamma^2}$ï¼Œæ‰€ä»¥è®­ç»ƒè¯¯å·®éš T çš„å‡å°è€ŒæŒ‡æ•°å‡å°</p>
<p>AdaBoost is doing a kind of steepest descent search to minimize training errorâ€˜s upper bound</p>
<p><strong>Generalization error</strong></p>
<p>generalization error is expected test errorï¼Œis the <em>probability</em> of misclassifying a new example</p>
<p>Freund and Schapire è¯æ˜æµ‹è¯•è¯¯å·®ä¸Šé™ä¸ T æœ‰å…³ï¼š<br>$$<br>\hat{Pr}[H(x)\not=y]+\tilde{O}(\sqrt\frac{Td}{m})<br>$$<br>$m$ : the size of the sample; $d$ : the VC- dimension of the base classifier space; $T$ : the number of rounds of boosting.</p>
<p>ä¸Šå¼è¡¨æ˜æµ‹è¯•è¯¯å·®éšç€ T çš„å¢åŠ è€Œå˜å¤§ï¼Œä½†æ˜¯å®é™…æƒ…å†µä¼¼ä¹ä¸ä¼šè¿‡æ‹Ÿåˆ</p>
<p>Schapireç­‰è¯æ˜ä¸Šé™ä¸marginæœ‰å…³ï¼Œç‹¬ç«‹äº T ï¼š</p>
<p>marginå°±æ˜¯åˆ†ç±»æ­£ç¡®å’Œåˆ†ç±»é”™è¯¯çš„Dçš„æƒé‡ä¹‹å·®ï¼š<br>$$<br>\begin{equation}<br>\begin{aligned}<br>margin_f(x,y) &amp;= \frac{yf(x)}{\sum_t|\alpha_t|} = \frac{y\sum_t\alpha_th_t(x)}{\sum_t|\alpha_t|}<br>\&amp;=\frac{1}{\sum_t|\alpha_t|}(\sum_{t:y=h_t(x)}\alpha_t - \sum_{t:y\not=h_t(x)}\alpha_t)<br>\end{aligned}<br>\end{equation}<br>$$<br>ä¸Šé™ï¼š<br>$$<br>\hat{Pr}[margin_f(x,y)\le\theta]+\tilde{O}(\sqrt\frac{d}{m\theta^2})<br>$$<br>for any $\theta&gt;0$ with high probability. (Lec16 P14)</p>
<p>åŸºäºmarginçš„æ¦‚å¿µï¼Œäº§ç”Ÿäº†ä¸€å †çš„ç®—æ³•ï¼Œæ¯”å¦‚æ„ŸçŸ¥æœºã€SVMä¹‹ç±»çš„</p>
<p><strong>æ„ŸçŸ¥æœº perceptron</strong></p>
<p>1957 Rosenblattï¼ŒLec16 P19</p>
<p>ä¸€ç§ Online Learning Modelï¼ŒäºŒå…ƒåˆ†ç±»çš„çº¿å½¢åˆ†ç±»æ¨¡å‹ï¼Œåˆ¤åˆ«æ–¹æ³•ï¼Œ$f(x)=sign(w*x+b)$ ã€‚å¾—å‡ºä¸€ä¸ªç‰¹å¾ç©ºé—´ä¸­çš„åˆ’åˆ†è¶…å¹³é¢separating hyperplaneã€‚</p>
<p><strong>åœ¨çº¿å­¦ä¹ </strong></p>
<p>Example arrive sequentially.</p>
<p>æ²¡æœ‰ä»»ä½•å‡è®¾ï¼šno distributional assumptions</p>
<p>ç›®æ ‡ï¼šæœ€å°åŒ–é”™è¯¯ä¸ªæ•°ï¼ˆå› ä¸ºè®­ç»ƒæ ·æœ¬ä¸æ˜¯ä¸€æ¬¡æ€§ç»™å‡ºï¼Œæ— æ³•è®¡ç®—è¯¯å·®ç‡ï¼‰</p>
<p>![Screen Shot 2020-05-21 at 9.27.53 AM](ç»Ÿè®¡å­¦ä¹ ç†è®º/Screen Shot 2020-05-21 at 9.27.53 AM.png)</p>
<h1 id="æ ¸æ–¹æ³•"><a href="#æ ¸æ–¹æ³•" class="headerlink" title="æ ¸æ–¹æ³•"></a>æ ¸æ–¹æ³•</h1><h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><h1 id="semi-supervised-learning"><a href="#semi-supervised-learning" class="headerlink" title="semi-supervised learning"></a>semi-supervised learning</h1><h1 id="ä¸»åŠ¨å­¦ä¹ "><a href="#ä¸»åŠ¨å­¦ä¹ " class="headerlink" title="ä¸»åŠ¨å­¦ä¹ "></a>ä¸»åŠ¨å­¦ä¹ </h1><h1 id="unsupervised-learning"><a href="#unsupervised-learning" class="headerlink" title="unsupervised learning"></a>unsupervised learning</h1><h1 id="deep-learning"><a href="#deep-learning" class="headerlink" title="deep learning"></a>deep learning</h1>
        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>TSHOGX</span>
                    </p>
                
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2020</span>
                    </p>
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E7%AC%94%E8%AE%B0/"># ç¬”è®°</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>Â· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2020/04/17/%E6%8A%95%E8%B5%84%E4%B8%8E%E9%87%91%E8%9E%8D%E5%B8%82%E5%9C%BA/">æŠ•èµ„ä¸é‡‘èå¸‚åœº</a>
            
            
            <a class="next" rel="next" href="/2020/04/16/%E5%BB%BA%E7%AD%91/">å»ºç­‘</a>
            
        </section>


    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>Â© TSHOGX | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>
</html>
